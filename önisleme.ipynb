{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MqjP-zVEYGNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1205c6-f6e8-4fec-8939-df73d867a8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#kütüphanelerin importlanması\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "9FlDN25fLilX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spectogram yolu oluşturulması ve spectogram fotografların yüklenmesi\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/spectrograms\"\n",
        "X = []\n",
        "y = []\n",
        "for i in range(10):\n",
        "    os.chdir(f\"{path}/{i}\")\n",
        "    for file in os.listdir():\n",
        "        image = cv2.imread(f\"{path}/{i}/{file}\")\n",
        "        image_resized = cv2.resize(image,(128, 96))\n",
        "    #JPEG array yapma\n",
        "        X.append(image_resized)\n",
        "        y.append(i)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(X[0].shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6oSm2wdXadcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0'ıncı indeksi gösterelim\n",
        "plt.imshow(X[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tfC620zhes7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x ve y nin veri setlerini oluşturalım\n",
        "X_train, X_temporary, y_train, y_temporary = train_test_split(X, y, train_size=0.8)\n",
        "\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temporary, y_temporary, train_size=0.5)"
      ],
      "metadata": {
        "id": "ZS7ow285gA6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_test[669])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q1kv1Y4Gkepn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#veri setindeki değişkenlerin uzunluklarını göstgerelim\n",
        "print(f'veri seti uzunluğu : {len(X)}')\n",
        "print(f'training veri setinin uzunluğu: {len(X_train)}')\n",
        "print(f'validation veri setinin uzunluğu: {len(X_val)}')\n",
        "print(f'test veri setinin uzunluğu: {len(X_test)}')"
      ],
      "metadata": {
        "id": "e563TySKlUyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#veri setinin 0-1 arası değer alması için normalizasyon (/255)uyguluyoruz\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "9l6LAE75l0Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0]"
      ],
      "metadata": {
        "id": "ei8Ss4WpmLKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_width = 25\n",
        "#image_height = 25"
      ],
      "metadata": {
        "id": "BSloZxqlCB0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for category in range(10):\n",
        "    max_img_number = 0\n",
        "    index = categories.index(category)\n",
        "    for image in os.listdir(f\"{path}/{category}\"):\n",
        "        if max_img_number == 1000:\n",
        "            break\n",
        "        img_path = f\"{path}/{category}/{image}\"\n",
        "        try:\n",
        "            img = cv2.imread(img_path,cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img,(128,128))\n",
        "            img = img/255   \n",
        "            images.append([index,img])\n",
        "            max_img_number += 1\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "dt6UON8ivJf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##model hazırlanamsı ve eğitimi"
      ],
      "metadata": {
        "id": "m9NAN4mi3I70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "57QzPpYP3_fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
        "from keras.models import Model,Sequential\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.optimizers import sgd_experimental\n",
        "from keras.optimizers import rmsprop_v2\n",
        "#from keras.optimizers import Adam\n",
        "#from keras.optimizers import sgd_experimental\n",
        "#from keras.optimizers import rmsprop_v2"
      ],
      "metadata": {
        "id": "tg7XL2ui3NOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "picture_size = 48\n",
        "folder_path = \"/content/drive/MyDrive/Colab Notebooks/spectrograms\"\n",
        "\n"
      ],
      "metadata": {
        "id": "N1gYx6r-3YkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_classes = 10\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#1st CNN layer\n",
        "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#2nd CNN layer\n",
        "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout (0.25))\n",
        "\n",
        "#3rd CNN layer\n",
        "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout (0.25))\n",
        "\n",
        "#4th CNN layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n"
      ],
      "metadata": {
        "id": "i_qo0FyO4b8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "\n",
        "#Fully connected 1st layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# Fully connected layer 2nd layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(no_of_classes, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "JVAaQlTW5GCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "#optimizer = adam_v2.Adam(learning_rate=lr, decay=lr/epochs)\n",
        "#opt = adam_v2(lr = 0.0001)\n",
        "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "epochs = 48\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "metadata": {
        "id": "XG3bE1oP5Khz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import Sequential,optimizers\n",
        "\n",
        "IMG_HEIGHT = 64\n",
        "IMG_WIDTH = 64\n",
        "\n",
        "def create_model(kernel_size: tuple, input_shape: tuple):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(IMG_WIDTH,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=(1,1),\n",
        "                  padding=\"same\",\n",
        "                  activation=\"relu\",\n",
        "                  input_shape=input_shape)           \n",
        "  )\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Conv2D(IMG_WIDTH/2,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=(1,1),\n",
        "                  padding=\"same\",\n",
        "                  activation=\"relu\",\n",
        "                  input_shape=input_shape)           \n",
        "  )\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu')),\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=optimizers.Adam(lr=0.0001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  return model"
      ],
      "metadata": {
        "id": "KXb_g9cS-cXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = create_model((3, 3), (IMG_WIDTH, IMG_HEIGHT, 1))\n",
        "results = my_model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "f6TwXRPK-hAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(results.history[\"loss\"], label=\"Loss\")\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4eq_kQcKD7ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "id": "VLQDamAhWXuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "iAL76LJ9WYcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7T_pkhSeWb9e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}